{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jzRKNe1iSlNW"
   },
   "source": [
    "This notebook will go through how to access and run code on youtube thumbnails\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6jhtQMGlmQ92",
    "outputId": "7061d714-8861-4148-e28e-6db6e5b5d7dc"
   },
   "outputs": [],
   "source": [
    "%pip install cmake\n",
    "%pip install requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hWF7z9hzncgL",
    "outputId": "2a6d78d2-313e-4cf8-8056-dcd430d7b3e3"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.listdir())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "id": "sLda1EAymkZs",
    "outputId": "4ac6af63-541b-422c-fa79-0dad57a6305b"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Path to the thumbnails folder\n",
    "thumbnails_folder = r'C:\\Users\\alexa\\Thesis\\complete thumbnails\\thumbnails'\n",
    "\n",
    "\n",
    "# List all files in the thumbnails folder\n",
    "files = os.listdir(thumbnails_folder)\n",
    "\n",
    "# Filter out non-image files (optional) and select 3 images\n",
    "image_files = [f for f in files if f.endswith(('.png', '.jpg', '.jpeg'))][:3]\n",
    "\n",
    "# Display the selected 3 images\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "for i, image_file in enumerate(image_files):\n",
    "    image_path = os.path.join(thumbnails_folder, image_file)\n",
    "    image = Image.open(image_path)\n",
    "\n",
    "    plt.subplot(1, 3, i + 1)\n",
    "    plt.imshow(image)\n",
    "    plt.title(image_file)\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hNYZqiPqqwcL",
    "outputId": "faa9f194-0f76-429a-e89e-77f0adeca4f4"
   },
   "outputs": [],
   "source": [
    "%pip install pytube opencv-python\n",
    "%pip install dlib imutils\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JEetv4CVZHfG",
    "outputId": "1d4046c5-9fae-400f-ccde-3616cdee7a9e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fj9YcAnsT4B_"
   },
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import io\n",
    "import time\n",
    "import base64\n",
    "import html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MaZIOR4WaT64"
   },
   "source": [
    "## Haar Cascade Classifier\n",
    "For this tutorial we will run a simple object detection algorithm called Haar Cascade on our images and video fetched from our webcam. OpenCV has a pre-trained Haar Cascade face detection model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZpA68lTrcvZs"
   },
   "outputs": [],
   "source": [
    "\n",
    "face_cascade = cv2.CascadeClassifier(cv2.samples.findFile(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Code for 3 Images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "TzhJmVCeq3Bz",
    "outputId": "b0420dd7-f98a-40c5-98ea-81d579a21432"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import dlib\n",
    "import pandas as pd\n",
    "\n",
    "# Path to the thumbnails folder\n",
    "thumbnails_folder = r'C:\\Users\\alexa\\Thesis\\complete thumbnails\\thumbnails'\n",
    "\n",
    "# Load the pre-trained dlib model for facial landmarks detection\n",
    "predictor_path = r\"C:\\Users\\alexa\\Thesis\\shape_predictor_68_face_landmarks.dat\\shape_predictor_68_face_landmarks.dat\"\n",
    "face_landmark_predictor = dlib.shape_predictor(predictor_path)\n",
    "\n",
    "# Initialize dlib's face detector\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "# Define AU weights for each emotion to compute confidence levels\n",
    "emotion_au_weights = {\n",
    "    'Happiness': {'AU12': 0.5, 'AU6': 0.5},\n",
    "    'Sadness': {'AU1': 0.3, 'AU4': 0.4, 'AU15': 0.3},\n",
    "    'Surprise': {'AU5': 0.5, 'AU26': 0.5},\n",
    "    'Disgust': {'AU9': 0.5, 'AU10': 0.5},\n",
    "    'Fear': {'AU4': 0.3, 'AU5': 0.3, 'AU7': 0.4},\n",
    "    'Anger': {'AU4': 0.5, 'AU7': 0.5},\n",
    "    'Neutral': {}\n",
    "}\n",
    "\n",
    "# Function to compute AUs based on landmarks\n",
    "def compute_facs_aus(landmarks):\n",
    "    # Extract key facial coordinates\n",
    "    left_eye_y = np.mean([landmarks.part(i).y for i in range(36, 42)])  # Left eye\n",
    "    right_eye_y = np.mean([landmarks.part(i).y for i in range(42, 48)])  # Right eye\n",
    "    mouth_top_y = np.mean([landmarks.part(i).y for i in range(48, 55)])  # Top of mouth\n",
    "    mouth_bottom_y = np.mean([landmarks.part(i).y for i in range(55, 60)])  # Bottom of mouth\n",
    "    left_eyebrow_y = np.mean([landmarks.part(i).y for i in range(17, 22)])  # Left eyebrow\n",
    "    right_eyebrow_y = np.mean([landmarks.part(i).y for i in range(22, 27)])  # Right eyebrow\n",
    "    nose_tip_y = landmarks.part(30).y  # Nose tip\n",
    "    upper_lip_y = landmarks.part(62).y  # Upper lip (central)\n",
    "    lower_lip_y = landmarks.part(66).y  # Lower lip (central)\n",
    "\n",
    "    mouth_corner_left = landmarks.part(48).y  # Left corner of mouth\n",
    "    mouth_corner_right = landmarks.part(54).y  # Right corner of mouth\n",
    "\n",
    "    # Define AUs based on specific facial regions\n",
    "    aus = {\n",
    "        'AU1': 'Inner Brow Raiser' if left_eyebrow_y < left_eye_y else 'None',\n",
    "        'AU2': 'Outer Brow Raiser' if left_eyebrow_y < left_eye_y - 5 else 'None',\n",
    "        'AU4': 'Brow Lowerer' if left_eyebrow_y > left_eye_y else 'None',\n",
    "        'AU5': 'Upper Lid Raiser' if left_eye_y < nose_tip_y else 'None',\n",
    "        'AU6': 'Cheek Raiser' if mouth_corner_left < mouth_top_y and mouth_corner_right < mouth_top_y else 'None',\n",
    "        'AU7': 'Lid Tightener' if left_eye_y > nose_tip_y else 'None',\n",
    "        'AU9': 'Nose Wrinkler' if nose_tip_y < upper_lip_y else 'None',\n",
    "        'AU10': 'Upper Lip Raiser' if upper_lip_y < lower_lip_y else 'None',\n",
    "        'AU12': 'Lip Corner Puller' if mouth_corner_left < mouth_top_y and mouth_corner_right < mouth_top_y else 'None',\n",
    "        'AU14': 'Dimpler' if mouth_corner_left > mouth_top_y and mouth_corner_right > mouth_top_y else 'None',\n",
    "        'AU15': 'Lip Corner Depressor' if mouth_corner_left > upper_lip_y and mouth_corner_right > upper_lip_y else 'None',\n",
    "        'AU17': 'Chin Raiser' if lower_lip_y > upper_lip_y else 'None',\n",
    "        'AU20': 'Lip Stretcher' if mouth_corner_left < upper_lip_y and mouth_corner_right < upper_lip_y else 'None',\n",
    "        'AU23': 'Lip Tightener' if abs(upper_lip_y - lower_lip_y) < 3 else 'None',\n",
    "        'AU25': 'Lips Part' if mouth_bottom_y - mouth_top_y > 5 else 'None',\n",
    "        'AU26': 'Jaw Drop' if mouth_bottom_y - mouth_top_y > 10 else 'None',\n",
    "        'AU28': 'Lip Suck' if lower_lip_y < upper_lip_y else 'None',\n",
    "        'AU45': 'Blink' if left_eye_y > nose_tip_y and right_eye_y > nose_tip_y else 'None'\n",
    "    }\n",
    "\n",
    "    # Combine AUs with their meanings into a string\n",
    "    active_aus = [f\"{au}: {description}\" for au, description in aus.items() if description != 'None']\n",
    "    return ', '.join(active_aus)\n",
    "\n",
    "# Function to compute confidence score for a given emotion\n",
    "def compute_emotion_confidence(active_aus, target_emotion):\n",
    "    weights = emotion_au_weights.get(target_emotion, {})\n",
    "    score = sum(weights.get(au, 0) for au in active_aus)\n",
    "    max_score = sum(weights.values())\n",
    "    confidence = (score / max_score) * 100 if max_score > 0 else 0\n",
    "    return confidence\n",
    "\n",
    "# Function to map AUs to emotions and return both emotion and confidence\n",
    "def map_aus_to_emotions(aus):\n",
    "    emotions = {\n",
    "        'Happiness': 'AU12' in aus and 'AU6' in aus,\n",
    "        'Sadness': 'AU1' in aus and 'AU4' in aus and 'AU15' in aus,\n",
    "        'Surprise': 'AU5' in aus and 'AU26' in aus,\n",
    "        'Disgust': 'AU9' in aus and 'AU10' in aus,\n",
    "        'Fear': 'AU4' in aus and 'AU5' in aus and 'AU7' in aus,\n",
    "        'Anger': 'AU4' in aus and 'AU7' in aus,\n",
    "        'Blinking': 'AU45' in aus\n",
    "    }\n",
    "\n",
    "    for emotion, condition in emotions.items():\n",
    "        if condition:\n",
    "            confidence = compute_emotion_confidence(aus, emotion)\n",
    "            return emotion, confidence\n",
    "\n",
    "    # Return Neutral if no other emotion is detected\n",
    "    return 'Neutral', 0\n",
    "\n",
    "# Function to draw blue boxes, green dots, and labels for landmarks\n",
    "def draw_boxes_and_landmarks(image, face, landmarks, face_count):\n",
    "    # Draw blue box around the face\n",
    "    cv2.rectangle(image, (face.left(), face.top()), (face.right(), face.bottom()), (255, 0, 0), 2)\n",
    "\n",
    "    # Add the face label at the top of the bounding box\n",
    "    label = f\"Face {face_count}\"\n",
    "    cv2.putText(image, label, (face.left(), face.top() - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "\n",
    "    # Draw green dots for facial landmarks\n",
    "    for i in range(68):\n",
    "        x = landmarks.part(i).x\n",
    "        y = landmarks.part(i).y\n",
    "        cv2.circle(image, (x, y), 2, (0, 255, 0), -1)\n",
    "\n",
    "# Function to process images, compute AUs, predict emotions, and save the results in CSV\n",
    "def process_images_and_save_csv(image_paths, csv_filename='face_aus_emotions_with_confidence.csv'):\n",
    "    all_face_data = []\n",
    "\n",
    "    for image_path in image_paths:\n",
    "        img = cv2.imread(image_path)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        faces = detector(gray)\n",
    "\n",
    "        face_count = 1\n",
    "        image_title = os.path.basename(image_path)\n",
    "\n",
    "        if len(faces) == 0:\n",
    "            row = [image_title, 'N/A', 'N/A', 'N/A', 'N/A']\n",
    "            all_face_data.append(row)\n",
    "        else:\n",
    "            for face in faces:\n",
    "                landmarks = face_landmark_predictor(gray, face)\n",
    "                draw_boxes_and_landmarks(img, face, landmarks, face_count)\n",
    "\n",
    "                aus = compute_facs_aus(landmarks)\n",
    "                active_aus = [au.split(':')[0] for au in aus.split(', ')]\n",
    "\n",
    "                emotion, confidence = map_aus_to_emotions(active_aus)\n",
    "\n",
    "                row = [image_title, f\"Face {face_count}\", aus, emotion, f\"{confidence:.2f}%\"]\n",
    "                all_face_data.append(row)\n",
    "                face_count += 1\n",
    "\n",
    "        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        plt.title(f'Processed: {image_title}')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "    columns = ['Image Title', 'Face', 'Active AUs', 'Predicted Emotion', 'Confidence Level']\n",
    "    df = pd.DataFrame(all_face_data, columns=columns)\n",
    "\n",
    "    df.to_csv(csv_filename, index=False)\n",
    "    print(f\"Table saved as {csv_filename}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Example usage with 3 images\n",
    "image_files = [os.path.join(thumbnails_folder, f) for f in os.listdir(thumbnails_folder) if f.endswith(('.png', '.jpg', '.jpeg'))][:3]\n",
    "df = process_images_and_save_csv(image_files)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0TaGTpQzhvJW"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main Code for 1500 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "tchM8Ow1hgPa",
    "outputId": "f7e97c67-d65e-4d1b-81c7-0efe960e2324"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import dlib\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Folder containing images\n",
    "thumbnails_folder = r'C:\\Users\\alexa\\Thesis\\complete thumbnails\\thumbnails'\n",
    "\n",
    "# Path to the dlib shape predictor\n",
    "predictor_path = r\"C:\\Users\\alexa\\Thesis\\shape_predictor_68_face_landmarks.dat\\shape_predictor_68_face_landmarks.dat\"\n",
    "face_landmark_predictor = dlib.shape_predictor(predictor_path)\n",
    "\n",
    "# Initialize dlib's face detector\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "# Define AU weights for each emotion to compute confidence levels\n",
    "emotion_au_weights = {\n",
    "    'Happiness': {'AU12': 0.5, 'AU6': 0.5},\n",
    "    'Sadness': {'AU1': 0.3, 'AU4': 0.4, 'AU15': 0.3},\n",
    "    'Surprise': {'AU5': 0.5, 'AU26': 0.5},\n",
    "    'Disgust': {'AU9': 0.5, 'AU10': 0.5},\n",
    "    'Fear': {'AU4': 0.3, 'AU5': 0.3, 'AU7': 0.4},\n",
    "    'Anger': {'AU4': 0.5, 'AU7': 0.5},\n",
    "    'Neutral': {}\n",
    "}\n",
    "\n",
    "# Function to compute AUs with intensity values (numerical)\n",
    "def compute_facs_aus(landmarks):\n",
    "    # Extract key facial coordinates\n",
    "    left_eye_y = np.mean([landmarks.part(i).y for i in range(36, 42)])  # Left eye\n",
    "    right_eye_y = np.mean([landmarks.part(i).y for i in range(42, 48)])  # Right eye\n",
    "    mouth_top_y = np.mean([landmarks.part(i).y for i in range(48, 55)])  # Top of mouth\n",
    "    mouth_bottom_y = np.mean([landmarks.part(i).y for i in range(55, 60)])  # Bottom of mouth\n",
    "    left_eyebrow_y = np.mean([landmarks.part(i).y for i in range(17, 22)])  # Left eyebrow\n",
    "    right_eyebrow_y = np.mean([landmarks.part(i).y for i in range(22, 27)])  # Right eyebrow\n",
    "    nose_tip_y = landmarks.part(30).y  # Nose tip\n",
    "    upper_lip_y = landmarks.part(62).y  # Upper lip (central)\n",
    "    lower_lip_y = landmarks.part(66).y  # Lower lip (central)\n",
    "\n",
    "    mouth_corner_left = landmarks.part(48).y  # Left corner of mouth\n",
    "    mouth_corner_right = landmarks.part(54).y  # Right corner of mouth\n",
    "\n",
    "    # Assigning intensity values for each AU based on facial feature distances\n",
    "    aus = {\n",
    "    'AU1': round(max(0, (left_eyebrow_y - left_eye_y) / (left_eye_y - nose_tip_y)), 4),\n",
    "    'AU2': round(max(0, (left_eyebrow_y - (left_eye_y - 5)) / (left_eye_y - nose_tip_y)), 4),\n",
    "    'AU4': round(max(0, abs(left_eyebrow_y - right_eyebrow_y) / (left_eye_y - nose_tip_y)), 4),\n",
    "    'AU5': round(max(0, (left_eye_y - nose_tip_y) / (nose_tip_y - upper_lip_y)), 4),\n",
    "    'AU6': round(max(0, (mouth_corner_left - mouth_top_y) / (mouth_bottom_y - mouth_top_y)), 4),\n",
    "    'AU7': round(max(0, (left_eye_y - nose_tip_y) / (nose_tip_y - upper_lip_y)), 4),\n",
    "    'AU9': round(max(0, (nose_tip_y - upper_lip_y) / (upper_lip_y - lower_lip_y + 0.0001)), 4),\n",
    "    'AU10': round(max(0, (upper_lip_y - lower_lip_y) / (mouth_bottom_y - mouth_top_y + 0.0001)), 4),\n",
    "    'AU12': round(max(0, (mouth_corner_left - mouth_top_y) / (mouth_bottom_y - mouth_top_y)), 4),\n",
    "    'AU14': round(max(0, abs(mouth_corner_left - mouth_corner_right) / (mouth_bottom_y - mouth_top_y)), 4),\n",
    "    'AU15': round(max(0, (mouth_corner_left - upper_lip_y) / (mouth_bottom_y - mouth_top_y)), 4),\n",
    "    'AU17': round(max(0, (lower_lip_y - upper_lip_y) / (mouth_bottom_y - mouth_top_y)), 4),\n",
    "    'AU20': round(max(0, (mouth_corner_left - upper_lip_y) / (mouth_bottom_y - mouth_top_y)), 4),\n",
    "    'AU23': round(max(0, abs(upper_lip_y - lower_lip_y) / (mouth_bottom_y - mouth_top_y)), 4),\n",
    "    'AU25': round(max(0, (mouth_bottom_y - mouth_top_y) / (nose_tip_y - upper_lip_y)), 4),\n",
    "    'AU26': round(max(0, (mouth_bottom_y - mouth_top_y) / (nose_tip_y - upper_lip_y)), 4),\n",
    "    'AU28': round(max(0, (lower_lip_y - upper_lip_y) / (mouth_bottom_y - mouth_top_y)), 4),\n",
    "    'AU45': round(max(0, (left_eye_y - nose_tip_y) / (nose_tip_y - upper_lip_y)), 4)\n",
    "        }\n",
    "\n",
    "\n",
    "    # Return AUs with their intensity values\n",
    "    return aus\n",
    "\n",
    "# Function to compute confidence score for a given emotion\n",
    "def compute_emotion_confidence(active_aus, target_emotion):\n",
    "    weights = emotion_au_weights.get(target_emotion, {})\n",
    "    score = sum(weights.get(au, 0) * active_aus.get(au, 0) for au in active_aus)\n",
    "    max_score = sum(weights.values())\n",
    "    confidence = (score / max_score) * 100 if max_score > 0 else 0\n",
    "    return confidence\n",
    "\n",
    "# Function to map AUs to emotions and return both emotion and confidence\n",
    "def map_aus_to_emotions(aus):\n",
    "    emotions = {\n",
    "        'Happiness': 'AU12' in aus and 'AU6' in aus,\n",
    "        'Sadness': 'AU1' in aus and 'AU4' in aus and 'AU15' in aus,\n",
    "        'Surprise': 'AU5' in aus and 'AU26' in aus,\n",
    "        'Disgust': 'AU9' in aus and 'AU10' in aus,\n",
    "        'Fear': 'AU4' in aus and 'AU5' in aus and 'AU7' in aus,\n",
    "        'Anger': 'AU4' in aus and 'AU7' in aus,\n",
    "        'Blinking': 'AU45' in aus\n",
    "    }\n",
    "\n",
    "    for emotion, condition in emotions.items():\n",
    "        if condition:\n",
    "            confidence = compute_emotion_confidence(aus, emotion)\n",
    "            return emotion, confidence\n",
    "\n",
    "    # Return Neutral if no other emotion is detected\n",
    "    return 'Neutral', 0\n",
    "\n",
    "# Function to draw blue boxes, green dots, and labels for landmarks\n",
    "def draw_boxes_and_landmarks(image, face, landmarks, face_count):\n",
    "    # Draw blue box around the face\n",
    "    cv2.rectangle(image, (face.left(), face.top()), (face.right(), face.bottom()), (255, 0, 0), 2)\n",
    "\n",
    "    # Add the face label at the top of the bounding box\n",
    "    label = f\"Face {face_count}\"\n",
    "    cv2.putText(image, label, (face.left(), face.top() - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "\n",
    "    # Draw green dots for facial landmarks\n",
    "    for i in range(68):\n",
    "        x = landmarks.part(i).x\n",
    "        y = landmarks.part(i).y\n",
    "        cv2.circle(image, (x, y), 2, (0, 255, 0), -1)\n",
    "\n",
    "# Folder to save processed images\n",
    "processed_images_folder = r'C:\\Users\\alexa\\Thesis\\processed_thumbnails'\n",
    "\n",
    "# Ensure the folder exists\n",
    "if not os.path.exists(processed_images_folder):\n",
    "    os.makedirs(processed_images_folder)\n",
    "\n",
    "def process_images_and_save_csv(image_paths, csv_filename='face_aus_emotions_with_confidence.csv'):\n",
    "    all_face_data = []\n",
    "    \n",
    "    random.shuffle(image_paths)\n",
    "    for image_path in image_paths:\n",
    "        img = cv2.imread(image_path)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        faces = detector(gray)\n",
    "\n",
    "        image_title = os.path.basename(image_path)\n",
    "\n",
    "        if len(faces) == 0:\n",
    "            row = [image_title, 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A']\n",
    "            all_face_data.append(row)\n",
    "        else:\n",
    "            for face in faces:\n",
    "                # Finding the largest face\n",
    "                largest_face = max(faces, key=lambda rect: rect.area())\n",
    "                landmarks = face_landmark_predictor(gray, largest_face)\n",
    "                draw_boxes_and_landmarks(img, largest_face, landmarks, 1)\n",
    "\n",
    "                aus = compute_facs_aus(landmarks)\n",
    "                active_aus = {au: value for au, value in aus.items() if value > 0}\n",
    "\n",
    "                emotion, confidence = map_aus_to_emotions(active_aus)\n",
    "\n",
    "                left_eye_coords = [(landmarks.part(i).x, landmarks.part(i).y) for i in range(36, 42)]\n",
    "                right_eye_coords = [(landmarks.part(i).x, landmarks.part(i).y) for i in range(42, 48)]\n",
    "                nose_coords = [(landmarks.part(i).x, landmarks.part(i).y) for i in range(27, 36)]\n",
    "                mouth_coords = [(landmarks.part(i).x, landmarks.part(i).y) for i in range(48, 68)]\n",
    "\n",
    "                row = [image_title, aus, emotion, f\"{confidence:.2f}%\",\n",
    "                       left_eye_coords, right_eye_coords, nose_coords, mouth_coords]\n",
    "                all_face_data.append(row)\n",
    "\n",
    "            # Save processed image\n",
    "            processed_image_path = os.path.join(processed_images_folder, image_title)\n",
    "            cv2.imwrite(processed_image_path, img)\n",
    "\n",
    "        df = pd.DataFrame(all_face_data, columns=['Image', 'AUs', 'Emotion', 'Confidence',\n",
    "                                              'Left Eye', 'Right Eye', 'Nose', 'Mouth'])\n",
    "        df.to_csv(csv_filename, index=False)\n",
    "\n",
    "\n",
    "\n",
    "        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        plt.title(f'Processed: {image_title}')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "    columns = ['Image Title', 'Active AUs', 'Predicted Emotion', 'Confidence Level',\n",
    "               'Left Eye Coordinates', 'Right Eye Coordinates', 'Nose Coordinates', 'Mouth Coordinates']\n",
    "    df = pd.DataFrame(all_face_data, columns=columns)\n",
    "\n",
    "    df.to_csv(csv_filename, index=False)\n",
    "    print(f\"Table saved as {csv_filename}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Example usage with 3k images\n",
    "image_files = [os.path.join(thumbnails_folder, f) for f in os.listdir(thumbnails_folder) if f.endswith(('.png', '.jpg', '.jpeg'))][:1500]\n",
    "df = process_images_and_save_csv(image_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder to save processed images\n",
    "\n",
    "processed_folder = r'C:\\Users\\alexa\\Thesis\\processed_thumbnails'\n",
    "os.makedirs(processed_folder, exist_ok=True)\n",
    "\n",
    "def process_images_and_save_csv(image_paths, csv_filename='face_aus_emotions_with_confidence.csv'):\n",
    "    all_face_data = []\n",
    "\n",
    "    print(f\"Processing {len(image_paths)} images...\")  # Debugging\n",
    "\n",
    "    for image_path in image_paths:\n",
    "        print(f\"Processing: {image_path}\")\n",
    "\n",
    "        img = cv2.imread(image_path)\n",
    "\n",
    "        if img is None:\n",
    "            print(f\" Failed to load image: {image_path}\")\n",
    "            continue  # Skip this image\n",
    "\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        faces = detector(gray)\n",
    "\n",
    "        image_title = os.path.basename(image_path)\n",
    "\n",
    "        if len(faces) == 0:\n",
    "            print(f\"⚠️ No faces detected in {image_title}\")\n",
    "            row = [image_title, 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A']\n",
    "            all_face_data.append(row)\n",
    "        else:\n",
    "            largest_face = max(faces, key=lambda rect: rect.area())\n",
    "            landmarks = face_landmark_predictor(gray, largest_face)\n",
    "            draw_boxes_and_landmarks(img, largest_face, landmarks, 1)\n",
    "\n",
    "            aus = compute_facs_aus(landmarks)\n",
    "            active_aus = {au: value for au, value in aus.items() if value > 0}\n",
    "            emotion, confidence = map_aus_to_emotions(active_aus)\n",
    "\n",
    "            row = [image_title, aus, emotion, f\"{confidence:.2f}%\"]\n",
    "            all_face_data.append(row)\n",
    "\n",
    "            processed_image_path = os.path.join(processed_folder, image_title)\n",
    "            success = cv2.imwrite(processed_image_path, img)\n",
    "\n",
    "            if success:\n",
    "                print(f\"✅ Saved: {processed_image_path}\")\n",
    "            else:\n",
    "                print(f\" Failed to save: {processed_image_path}\")\n",
    "\n",
    "    print(\"Processing complete.\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
